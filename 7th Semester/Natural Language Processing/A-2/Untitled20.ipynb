{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1T08JOvwdkEnqs55-0E1nHSow-WVAaL-U","authorship_tag":"ABX9TyPofW1SFwZtXbCHh5oAMPgt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wFawJgDPdsw","executionInfo":{"status":"ok","timestamp":1703093076796,"user_tz":-300,"elapsed":378,"user":{"displayName":"M Muaz Shahzad","userId":"16180681758969111463"}},"outputId":"29da4b7f-b829-4879-c1f5-099dbd228ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Emails:\n","muazshahzad667@gmail.com is a valid email address\n","bahria@university.edu is a valid email address\n","hamzatahir@wrong.net is not a valid email address\n","\n","Phone Numbers:\n","+923001234567 is not a valid phone number\n","0312-3456789 is a valid phone number\n","042-1234567 is not a valid phone number\n","invalid-number is not a valid phone number\n"]}],"source":["import re\n","\n","# a. Email address of any type. Domain .com or .edu\n","email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.(com|edu)\\b')\n","\n","# b. Karachi or Lahore phone number\n","# Assuming a Pakistani phone number format (e.g., +92-XXX-XXXXXXX or 03XX-XXXXXXX)\n","phone_pattern = re.compile(r'\\b((\\+92)|0)(3[0-9]{2}|21[0-9]|22[0-9])-[0-9]{7}\\b')\n","\n","# Test cases\n","emails = [\"muazshahzad667@gmail.com\", \"bahria@university.edu\", \"hamzatahir@wrong.net\"]\n","phone_numbers = [\"+923001234567\", \"0312-3456789\", \"042-1234567\", \"invalid-number\"]\n","\n","print(\"Emails:\")\n","for email in emails:\n","    if email_pattern.match(email):\n","        print(f\"{email} is a valid email address\")\n","    else:\n","        print(f\"{email} is not a valid email address\")\n","\n","print(\"\\nPhone Numbers:\")\n","for phone_number in phone_numbers:\n","    if phone_pattern.match(phone_number):\n","        print(f\"{phone_number} is a valid phone number\")\n","    else:\n","        print(f\"{phone_number} is not a valid phone number\")\n"]},{"cell_type":"code","source":["import gensim\n","import numpy as np\n","\n","sentences = gensim.models.word2vec.LineSentence('A2_text.txt')\n","\n","skip_gram_model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n","cbow_model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n","\n","word_pairs = [('vibrant', 'flowers'), ('freshly', 'baked '), ('mountains', 'painted')]\n","\n","def cosine_similarity(v1, v2):\n","    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n","\n","for w1, w2 in word_pairs:\n","    if w1 in skip_gram_model.wv and w2 in skip_gram_model.wv and w1 in cbow_model.wv and w2 in cbow_model.wv:\n","        v1_sg = skip_gram_model.wv[w1]\n","        v2_sg = skip_gram_model.wv[w2]\n","        v1_cbow = cbow_model.wv[w1]\n","        v2_cbow = cbow_model.wv[w2]\n","\n","        sim_sg = cosine_similarity(v1_sg, v2_sg)\n","        sim_cbow = cosine_similarity(v1_cbow, v2_cbow)\n","\n","        print(f\"\\nCosine similarity between {w1} and {w2} using skip-gram: {sim_sg:.3f}\")\n","        print(f\"\\nCosine similarity between {w1} and {w2} using CBOW: {sim_cbow:.3f}\")\n","    else:\n","        print(f\"\\nOne or both of the words '{w1}' and '{w2}' not present in the vocabulary.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dZ6AwN1R35h","executionInfo":{"status":"ok","timestamp":1703094198748,"user_tz":-300,"elapsed":452,"user":{"displayName":"M Muaz Shahzad","userId":"16180681758969111463"}},"outputId":"f4eca6a0-7d86-440b-9a52-48cfde2c800e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cosine similarity between vibrant and flowers using skip-gram: 0.119\n","\n","Cosine similarity between vibrant and flowers using CBOW: 0.119\n","\n","One or both of the words 'freshly' and 'baked ' not present in the vocabulary.\n","\n","One or both of the words 'mountains' and 'painted' not present in the vocabulary.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","# Sample sentences and their sentiments (1 for positive, 0 for negative)\n","sentences = [\n","   \"The concert exceeded my expectations!\",\n","\"The vacation was absolutely incredible.\",\n","\"I appreciate the efficiency of this application.\",\n","\"The customer support was disappointing.\",\n","\"The play was mediocre, lacking excitement.\",\n","]\n","labels = np.array([1, 1, 0, 0, 1])\n","\n","# Tokenize and pad the sequences\n","tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded_sequences = pad_sequences(sequences, maxlen=10, padding='post', truncating='post')\n","\n","# LSTM Model\n","model = Sequential([\n","    Embedding(100, 16, input_length=10),\n","    LSTM(32, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dropout(0.2),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(padded_sequences, labels, epochs=15, batch_size=2, verbose=1)\n","\n","# Evaluate the model on new sentences\n","test_sentences = [\n","   \"The play was awful.\",\n","\"The presentation was uninteresting.\",\n","\"I enjoy alot in the concert.\",\n","]\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","padded_test_sequences = pad_sequences(test_sequences, maxlen=10, padding='post', truncating='post')\n","\n","predictions = model.predict(padded_test_sequences)\n","\n","# Print sentences and their predicted sentiments\n","for idx, sentence in enumerate(test_sentences):\n","    sentiment = \"Positive\" if predictions[idx][0] > 0.7 else \"Negative\"\n","    print(f\"\\nSentence: '{sentence}' -> Predicted Sentiment: {sentiment} (Probability: {predictions[idx][0]:.2f})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEkBygQMXG8d","executionInfo":{"status":"ok","timestamp":1703095183941,"user_tz":-300,"elapsed":6743,"user":{"displayName":"M Muaz Shahzad","userId":"16180681758969111463"}},"outputId":"45af8ccc-258f-4b1f-a8e8-96034c48e855"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","3/3 [==============================] - 4s 13ms/step - loss: 0.6941 - accuracy: 0.4000\n","Epoch 2/15\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.6000\n","Epoch 3/15\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.6000\n","Epoch 4/15\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.6000\n","Epoch 5/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.6000\n","Epoch 6/15\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.6000\n","Epoch 7/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.6000\n","Epoch 8/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.6000\n","Epoch 9/15\n","3/3 [==============================] - 0s 17ms/step - loss: 0.6786 - accuracy: 0.6000\n","Epoch 10/15\n","3/3 [==============================] - 0s 16ms/step - loss: 0.6796 - accuracy: 0.6000\n","Epoch 11/15\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6713 - accuracy: 0.6000\n","Epoch 12/15\n","3/3 [==============================] - 0s 14ms/step - loss: 0.6684 - accuracy: 0.6000\n","Epoch 13/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6631 - accuracy: 0.6000\n","Epoch 14/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6515 - accuracy: 0.6000\n","Epoch 15/15\n","3/3 [==============================] - 0s 13ms/step - loss: 0.6433 - accuracy: 0.6000\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ab0983088b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 979ms/step\n","\n","Sentence: 'The play was awful.' -> Predicted Sentiment: Negative (Probability: 0.58)\n","\n","Sentence: 'The presentation was uninteresting.' -> Predicted Sentiment: Negative (Probability: 0.57)\n","\n","Sentence: 'I enjoy alot in the concert.' -> Predicted Sentiment: Negative (Probability: 0.55)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"J8SXw-kfXMME"},"execution_count":null,"outputs":[]}]}